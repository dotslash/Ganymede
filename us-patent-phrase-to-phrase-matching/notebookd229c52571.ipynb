{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d790d2",
   "metadata": {
    "papermill": {
     "duration": 0.005756,
     "end_time": "2023-04-25T09:09:56.051959",
     "exception": false,
     "start_time": "2023-04-25T09:09:56.046203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About notebook\n",
    "\n",
    "This is pretty much a clone of https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners. But the original notebook cannot be submitted for the competiotion because it does pip install and also downloads some pretrained model - ie. needs the internet. I took some learnings from https://www.kaggle.com/code/miwojc/getting-started-with-nlp-offline-version/notebook and was able to modify the notebook and get to a submittable notebook\n",
    "\n",
    "\n",
    "# Inputs\n",
    "1) competition data: If i tag the notebook to the competition, kaggle automatically downloads the input,out data to the environment where the notebook runs\n",
    "2) pre trained model: I randomly found someone created a dataset for debertav3small - pretrained model. Later I have more details on how the model is used\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4555e",
   "metadata": {
    "papermill": {
     "duration": 0.004201,
     "end_time": "2023-04-25T09:09:56.060931",
     "exception": false,
     "start_time": "2023-04-25T09:09:56.056730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load pretrained debertav3small model and create a tokenizer with it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a006118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:56.072415Z",
     "iopub.status.busy": "2023-04-25T09:09:56.071596Z",
     "iopub.status.idle": "2023-04-25T09:09:56.082728Z",
     "shell.execute_reply": "2023-04-25T09:09:56.081843Z"
    },
    "papermill": {
     "duration": 0.019477,
     "end_time": "2023-04-25T09:09:56.084868",
     "exception": false,
     "start_time": "2023-04-25T09:09:56.065391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# I get the following annoying warning all the time\n",
    "# huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "# To disable this warning, you can either:\n",
    "#  - Avoid using `tokenizers` before the fork if possible\n",
    "#  - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c857ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:56.095995Z",
     "iopub.status.busy": "2023-04-25T09:09:56.095071Z",
     "iopub.status.idle": "2023-04-25T09:09:59.429062Z",
     "shell.execute_reply": "2023-04-25T09:09:59.427933Z"
    },
    "papermill": {
     "duration": 3.342351,
     "end_time": "2023-04-25T09:09:59.431857",
     "exception": false,
     "start_time": "2023-04-25T09:09:56.089506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "# model_nm = 'microsoft/deberta-v3-small'\n",
    "# model_nm = '../input/debertav3small/checkpoint'\n",
    "model_nm = '../input/deberta-v3-large'\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2df64e",
   "metadata": {
    "papermill": {
     "duration": 0.004793,
     "end_time": "2023-04-25T09:09:59.441993",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.437200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "tokz.tokenize(string)\n",
    "* tokenizes the sentence into words\n",
    "* beginining of each word is prefixed by ▁ in the tokenized word\n",
    "* unknown words are broken into smaller parts. See the output of the below snippet\n",
    "\n",
    "tokx(string)\n",
    "* tokenizes the sentence into words and returns a vector of integer ids that can be used for nlp training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379e559c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.453152Z",
     "iopub.status.busy": "2023-04-25T09:09:59.452609Z",
     "iopub.status.idle": "2023-04-25T09:09:59.460970Z",
     "shell.execute_reply": "2023-04-25T09:09:59.459673Z"
    },
    "papermill": {
     "duration": 0.01632,
     "end_time": "2023-04-25T09:09:59.463080",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.446760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁today', \"'\", 's', '▁a', '▁nice', '▁day']\n",
      "{'input_ids': [1, 561, 280, 268, 266, 1085, 406, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokz.tokenize(\"today's a nice day\"))\n",
    "print(tokz(\"today's a nice day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534a0d6",
   "metadata": {
    "papermill": {
     "duration": 0.004587,
     "end_time": "2023-04-25T09:09:59.472618",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.468031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Import the kaggle training, eval datasets as pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5b05e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.483730Z",
     "iopub.status.busy": "2023-04-25T09:09:59.483444Z",
     "iopub.status.idle": "2023-04-25T09:09:59.587093Z",
     "shell.execute_reply": "2023-04-25T09:09:59.585836Z"
    },
    "papermill": {
     "duration": 0.112004,
     "end_time": "2023-04-25T09:09:59.589614",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.477610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = Path(\"/kaggle/input/us-patent-phrase-to-phrase-matching\")\n",
    "full_train_df = pd.read_csv(f'{dataset_path}/train.csv')\n",
    "eval_df = pd.read_csv(dataset_path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f2286c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.601312Z",
     "iopub.status.busy": "2023-04-25T09:09:59.601005Z",
     "iopub.status.idle": "2023-04-25T09:09:59.625171Z",
     "shell.execute_reply": "2023-04-25T09:09:59.624155Z"
    },
    "papermill": {
     "duration": 0.032809,
     "end_time": "2023-04-25T09:09:59.627655",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.594846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e48b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.640918Z",
     "iopub.status.busy": "2023-04-25T09:09:59.640613Z",
     "iopub.status.idle": "2023-04-25T09:09:59.699584Z",
     "shell.execute_reply": "2023-04-25T09:09:59.698577Z"
    },
    "papermill": {
     "duration": 0.068749,
     "end_time": "2023-04-25T09:09:59.701835",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.633086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37921a7d",
   "metadata": {
    "papermill": {
     "duration": 0.005195,
     "end_time": "2023-04-25T09:09:59.712351",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.707156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Debug: What is `include=` in describe\n",
    "* what all types of objects should the summary be described for\n",
    "* default is numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59181ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.723895Z",
     "iopub.status.busy": "2023-04-25T09:09:59.723577Z",
     "iopub.status.idle": "2023-04-25T09:09:59.777588Z",
     "shell.execute_reply": "2023-04-25T09:09:59.775616Z"
    },
    "papermill": {
     "duration": 0.062533,
     "end_time": "2023-04-25T09:09:59.780135",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.717602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context  \\\n",
       "count              36473                        36473        36473   36473   \n",
       "unique             36473                          733        29340     106   \n",
       "top     37d61fd2272659b1  component composite coating  composition     H01   \n",
       "freq                   1                          152           24    2186   \n",
       "mean                 NaN                          NaN          NaN     NaN   \n",
       "std                  NaN                          NaN          NaN     NaN   \n",
       "min                  NaN                          NaN          NaN     NaN   \n",
       "25%                  NaN                          NaN          NaN     NaN   \n",
       "50%                  NaN                          NaN          NaN     NaN   \n",
       "75%                  NaN                          NaN          NaN     NaN   \n",
       "max                  NaN                          NaN          NaN     NaN   \n",
       "\n",
       "               score  \n",
       "count   36473.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.362062  \n",
       "std         0.258335  \n",
       "min         0.000000  \n",
       "25%         0.250000  \n",
       "50%         0.250000  \n",
       "75%         0.500000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fd35c",
   "metadata": {
    "papermill": {
     "duration": 0.005864,
     "end_time": "2023-04-25T09:09:59.791852",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.785988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenization and creating the input\n",
    "* we create a new input column that is `\"TEXT1: <context>; TEXT2: <target>; ANC1: <anchor>\n",
    "* we then convert to a Dataset type and tokenize this to numbers\n",
    "* TODO: what is the impact of calling the placeholders TEXT1, TEXT2? The anchor is an opaque string that indicates the patent subject. Would it make sense to leverage it somehow? Why/Why not?\n",
    "\n",
    "datasets.Dataset is the rage\n",
    "* It seems the preferred way to deal with \"datasets\" is this library called datasets. \n",
    "* We convert the dataframes into Dataset type.\n",
    "* We rename the output label from score to label because thats what the transformers library's Trainer class likes.\n",
    "* Then also create a train-test split. Apparently random is not great. Quoting the original notebook from which this is taken\n",
    "> In practice, a random split like we've used here might not be a good idea -- here's what Dr Rachel Thomas has to say about it:\n",
    ">\n",
    "> \"One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a train_test_split method, this method takes a random subset of the data, which is a poor choice for many real-world problems.\"\n",
    ">\n",
    "> I strongly recommend reading her article [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) to more fully understand this critical topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc1934d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:09:59.803994Z",
     "iopub.status.busy": "2023-04-25T09:09:59.803684Z",
     "iopub.status.idle": "2023-04-25T09:10:03.134453Z",
     "shell.execute_reply": "2023-04-25T09:10:03.133526Z"
    },
    "papermill": {
     "duration": 3.339332,
     "end_time": "2023-04-25T09:10:03.136767",
     "exception": false,
     "start_time": "2023-04-25T09:09:59.797435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ad4dd4300d4f8da9453c0491b269fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cae4f0472c4caebe08797536fbcd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "def create_ds(df):\n",
    "    def tok_func(x): return tokz(x[\"input\"])\n",
    "    df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n",
    "    ds = Dataset.from_pandas(df).map(tok_func, batched=True)\n",
    "    if 'score' in df.columns:\n",
    "        # transformers library wants the output label to be label and not score\n",
    "        # score column is there only for the train set and not eval set. So do a check before\n",
    "        # the rename\n",
    "        ds = ds.rename_column('score', 'label')\n",
    "    return ds\n",
    "\n",
    "\n",
    "full_train_ds = create_ds(full_train_df)\n",
    "eval_ds = create_ds(eval_df)\n",
    "train_test_split = full_train_ds.train_test_split(0.25, seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86a146",
   "metadata": {
    "papermill": {
     "duration": 0.005661,
     "end_time": "2023-04-25T09:10:03.148243",
     "exception": false,
     "start_time": "2023-04-25T09:10:03.142582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Correlation: While training or while submission the we need to know the accuracy. define a correlation function to pass to the model the function that emits the accuracy of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d861dfd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:10:03.162282Z",
     "iopub.status.busy": "2023-04-25T09:10:03.160592Z",
     "iopub.status.idle": "2023-04-25T09:10:03.167321Z",
     "shell.execute_reply": "2023-04-25T09:10:03.166269Z"
    },
    "papermill": {
     "duration": 0.015735,
     "end_time": "2023-04-25T09:10:03.169519",
     "exception": false,
     "start_time": "2023-04-25T09:10:03.153784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def corr(x,y): \n",
    "    return np.corrcoef(x,y)[0][1]\n",
    "\n",
    "def corr_d(eval_pred): \n",
    "    return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bde6570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:10:03.182036Z",
     "iopub.status.busy": "2023-04-25T09:10:03.181713Z",
     "iopub.status.idle": "2023-04-25T09:10:13.715807Z",
     "shell.execute_reply": "2023-04-25T09:10:13.714570Z"
    },
    "papermill": {
     "duration": 10.544037,
     "end_time": "2023-04-25T09:10:13.719035",
     "exception": false,
     "start_time": "2023-04-25T09:10:03.174998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "# TODO: Learn how to do hyperparam search/tuning\n",
    "\n",
    "\n",
    "# bs=128: We do gradient descent on 128 samples at a time.\n",
    "# epochs=4: The model is trained with the full dataset 4 times\n",
    "# So if we have 1024 samples, we do gradient descent for 128 samples at a time\n",
    "# and 4 times => 32 gradient descents\n",
    "bs = 32\n",
    "epochs = 4 # TODO: should this be 8? What is the right number? \n",
    "# TODO: I dont know what is a good value here for learning rate. What is too small? What is too large?\n",
    "lr = 8e-5\n",
    "\n",
    "args = TrainingArguments(\n",
    "    'outputs', \n",
    "    learning_rate=lr, \n",
    "    warmup_ratio=0.1, # TODO: why?\n",
    "    # IIUC to avoid overfitting we cut down the learning rate using some cosine formula. \n",
    "    # learning_rate(epoch_number) = (lr/2)(1+cos(pi*epoch_number/total_epochs)). So the \n",
    "    # learning rate keeps getting smaller\n",
    "    # TODO: why all this cosine stuff. Why not lr*(1-(epoch_number/total_epochs))?\n",
    "    lr_scheduler_type='cosine', # TODO: why?\n",
    "    fp16=True,\n",
    "    # model is evaluated after each epoch. This makes more sense if we have hyper param tuning i think\n",
    "    # E.g we can have some settings to early stop the training if its degrading\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs*2, # TODO: why?\n",
    "    num_train_epochs=epochs,# TODO: why?\n",
    "    # TODO: why? I vaguely remember that larger weights imply that models are more \"decisive\"\n",
    "    # and often predict strong values E.g sigmoid function output is between 0 to 1. large weights result\n",
    "    # in sigmoid(f(X)) being very close to 0 or very close to 1. IOW: likely change of overfitting\n",
    "    # So \"artificially\" make the weights smaller as we train with more and more data.\n",
    "    # TODO: I think the dataset is pretty small \"here\" and we have \"only\" 4 epochs. So is that relevant?\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba1a59",
   "metadata": {
    "papermill": {
     "duration": 0.005834,
     "end_time": "2023-04-25T09:10:13.730704",
     "exception": false,
     "start_time": "2023-04-25T09:10:13.724870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the sequence classification model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd08671e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:10:13.743648Z",
     "iopub.status.busy": "2023-04-25T09:10:13.743309Z",
     "iopub.status.idle": "2023-04-25T09:10:32.139084Z",
     "shell.execute_reply": "2023-04-25T09:10:32.137907Z"
    },
    "papermill": {
     "duration": 18.405282,
     "end_time": "2023-04-25T09:10:32.141726",
     "exception": false,
     "start_time": "2023-04-25T09:10:13.736444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ../input/deberta-v3-large and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    args, \n",
    "    train_dataset=train_test_split['train'], \n",
    "    eval_dataset=train_test_split['test'],\n",
    "    tokenizer=tokz, \n",
    "    compute_metrics=corr_d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966c9f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T09:10:32.155292Z",
     "iopub.status.busy": "2023-04-25T09:10:32.154969Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-04-25T09:10:32.147918",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='429' max='1712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 429/1712 06:24 < 19:14, 1.11 it/s, Epoch 1/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/72 00:06 < 00:16, 3.07 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9dfbe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "\n",
    "preds = np.clip(preds, 0, 1) # Outputs are not 0-1. So clip them\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1e1cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(preds[:10])\n",
    "print(preds[:,0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c0e76",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds[:,0]\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003c356",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-25T09:09:46.176964",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}